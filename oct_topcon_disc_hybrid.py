import os, re, csv, sys, argparse, glob
from pathlib import Path
import cv2, numpy as np

# Tesseractè‡ªå‹•è¨­å®š
try:
    import tesseract_config  # è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«
    import pytesseract
    TESS_OK=True
except ImportError:
    try:
        import pytesseract
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: æ‰‹å‹•ãƒ‘ã‚¹è¨­å®š
        pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe'
        TESS_OK=True
    except Exception:
        TESS_OK=False

ENC="utf-8-sig"

# ---------- å…±é€š ----------
def read_img(p: Path):
    arr=np.fromfile(str(p), np.uint8); return cv2.imdecode(arr, cv2.IMREAD_COLOR)

def norm(t:str)->str:
    t=t or ""
    return (t.replace("\u3000"," ").replace("ã›","um").replace("Î¼m","um").replace("Âµm","um")
             .replace("ãŸ","mm2").replace("mmÂ²","mm2").replace("ã£","mm3").replace("mmÂ³","mm3")
             .replace("ï¼š",":").replace("ï¼Œ",",").replace("â€”","-").replace("âˆ’","-"))

def ocr_df(img, psm=6, lang="jpn+eng"):
    if not TESS_OK: return None, None
    g=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    H,W=g.shape
    
    # è¤‡æ•°è§£åƒåº¦ã§è©¦è¡Œï¼ˆç²¾åº¦å‘ä¸Šï¼‰
    best_df = None
    best_score = 0
    
    for target_size in [1800, 2400, 3000]:  # è¤‡æ•°è§£åƒåº¦è©¦è¡Œ
        if max(H,W) < target_size:
            s = target_size/max(H,W)
            g_resized = cv2.resize(g, (int(W*s), int(H*s)), cv2.INTER_CUBIC)
        else:
            g_resized = g.copy()
        
        # ç”»åƒå‰å‡¦ç†å¼·åŒ–
        # 1. ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆèª¿æ•´
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
        g_enhanced = clahe.apply(g_resized)
        
        # 2. ã‚¬ã‚¦ã‚·ã‚¢ãƒ³ãƒ•ã‚£ãƒ«ã‚¿ã§ãƒã‚¤ã‚ºé™¤å»
        g_filtered = cv2.GaussianBlur(g_enhanced, (3,3), 0)
        
        # 3. ã‚·ãƒ£ãƒ¼ãƒ—ãƒ‹ãƒ³ã‚°
        kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])
        g_sharp = cv2.filter2D(g_filtered, -1, kernel)
        
        # 4. äºŒå€¤åŒ–
        th = cv2.threshold(g_sharp, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)[1]
        
        # è¤‡æ•°PSMãƒ¢ãƒ¼ãƒ‰ã§è©¦è¡Œ
        for psm_mode in [psm, 6, 8, 13]:  # æŒ‡å®šPSM + ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            try:
                df = pytesseract.image_to_data(th, lang=lang, config=f"--oem 3 --psm {psm_mode}",
                                             output_type=pytesseract.Output.DATAFRAME)
                df = df.dropna(subset=["text"])
                df["text"] = df["text"].astype(str).str.strip()
                df = df[df["text"]!=""]
                
                # å“è³ªã‚¹ã‚³ã‚¢è¨ˆç®—ï¼ˆæ•°å€¤ã®å¤šã•ã¨ä¿¡é ¼åº¦ã§è©•ä¾¡ï¼‰
                score = len(df) * df['conf'].mean() if len(df) > 0 and 'conf' in df.columns else 0
                
                if score > best_score:
                    best_df = df
                    best_score = score
                    best_th = th
                    
            except Exception:
                continue
                
        # æœ€åˆã®è§£åƒåº¦ã§ååˆ†ãªçµæœãŒå¾—ã‚‰ã‚ŒãŸå ´åˆã¯çµ‚äº†
        if best_score > 1000:  # é–¾å€¤ã¯èª¿æ•´å¯èƒ½
            break
    
    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†
    if best_df is not None:
        return best_df, best_th if 'best_th' in locals() else th
    else:
        # åŸºæœ¬å‡¦ç†ï¼ˆå¾“æ¥æ–¹å¼ï¼‰
        if max(H,W)<1800:
            s=1800/max(H,W); g=cv2.resize(g,(int(W*s),int(H*s)), cv2.INTER_CUBIC)
        th=cv2.threshold(g,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)[1]
        df=pytesseract.image_to_data(th, lang=lang, config=f"--oem 3 --psm {psm}",
                                     output_type=pytesseract.Output.DATAFRAME)
        df=df.dropna(subset=["text"])
        df["text"]=df["text"].astype(str).str.strip()
        df=df[df["text"]!=""]
        return df, th

def bbox_of_line(df, pattern):
    for (blk,par,ln), g in df.groupby(["block_num","par_num","line_num"]):
        line=" ".join(g["text"].tolist())
        if re.search(pattern, line, re.I):
            x1=int(min(g["left"])); y1=int(min(g["top"]))
            x2=int(max(g["left"]+g["width"])); y2=int(max(g["top"]+g["height"]))
            return (x1,y1,x2,y2), line
    return None, ""

def crop_rect(img, x1,y1,x2,y2, pad=(0,0,0,0)):
    l,t,r,b = pad
    H,W = img.shape[:2]
    x1=max(0,x1-l); y1=max(0,y1-t); x2=min(W,x2+r); y2=min(H,y2+b)
    return img[y1:y2, x1:x2]

def debug_dump(dirp: Path, name: str, im=None, txt=None):
    if not dirp: return
    dirp.mkdir(parents=True, exist_ok=True)
    if im is not None: cv2.imwrite(str(dirp/f"{name}.png"), im)
    if txt is not None: (dirp/f"{name}.txt").write_text(txt, encoding="utf-8")

def numeric_tokens(df):
    out=[]
    for _,r in df.iterrows():
        s=str(r["text"])
        if re.fullmatch(r"\d{1,3}(?:\.\d+)?", s):
            out.append((int(r["left"]), int(r["top"]), int(r["width"]), int(r["height"]), s))
    return out

def pick_row_values(df_roi, y, band=35, expect=2):  # bandèª¿æ•´: 30â†’35
    """åŒã˜Yå¸¯ã«ã‚ã‚‹æ•°å€¤ã‚’xæ˜‡é †ã§è¿”ã™ï¼ˆå·¦=OD, å³=OSï¼‰"""
    nums = []
    for x,yy,w,h,s in numeric_tokens(df_roi):
        cy = yy + h/2
        if abs(cy - y) <= band:
            nums.append((x, s))
    nums.sort(key=lambda z:z[0])
    vals=[v for _,v in nums]
    return (vals[:expect] + [""]*expect)[:expect]

def keep_in(v, lo, hi):
    try:
        x=float(v); 
        return v if (lo is None or x>=lo) and (hi is None or x<=hi) else ""
    except: return ""

# ---------- æŠ½å‡ºï¼ˆOCT Disc Reportï¼‰ ----------
def extract_ss(df) -> tuple[str,str]:
    """Signal StrengthæŠ½å‡ºã®æ”¹è‰¯ç‰ˆï¼šè¤‡æ•°ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ»ç¯„å›²ãƒã‚§ãƒƒã‚¯å¼·åŒ–"""
    
    # è¤‡æ•°ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è©¦è¡Œ
    patterns = [
        r"TopQ\s*Image\s*Quality",
        r"Image\s*Quality", 
        r"Signal\s*Strength",
        r"SS",
        r"Quality\s*Index",
        r"QI"
    ]
    
    for pattern in patterns:
        for (blk,par,ln), g in df.groupby(["block_num","par_num","line_num"]):
            line=" ".join(g["text"].tolist())
            if re.search(pattern, line, re.I):
                # æ•°å€¤æŠ½å‡ºãƒ‘ã‚¿ãƒ¼ãƒ³ã‚‚å¼·åŒ–
                nums = []
                # 2-3æ¡ã®æ•°å€¤ã‚’æŠ½å‡º
                for match in re.finditer(r"(\d{2,3})", line):
                    val = int(match.group(1))
                    # Signal Strengthã®å¦¥å½“ç¯„å›²ï¼ˆ20-100ï¼‰
                    if 20 <= val <= 100:
                        nums.append(match.group(1))
                
                if len(nums) >= 2: 
                    return nums[0], nums[1]
                elif len(nums) == 1:
                    # 1ã¤ã—ã‹ãªã„å ´åˆã¯ã€è¿‘éš£è¡Œã‚‚æ¤œç´¢
                    nearby_nums = _search_nearby_ss(df, blk, par, ln)
                    if nearby_nums:
                        return nums[0], nearby_nums
    
    return "",""

def _search_nearby_ss(df, target_blk: int, target_par: int, target_ln: int) -> str:
    """è¿‘éš£è¡Œã‹ã‚‰Signal Strengthã®è¿½åŠ å€¤ã‚’æ¤œç´¢"""
    for (blk,par,ln), g in df.groupby(["block_num","par_num","line_num"]):
        # åŒã˜ãƒ–ãƒ­ãƒƒã‚¯ãƒ»æ®µè½ã§è¿‘ã„è¡Œç•ªå·
        if blk == target_blk and par == target_par and abs(ln - target_ln) <= 2:
            line=" ".join(g["text"].tolist())
            for match in re.finditer(r"(\d{2,3})", line):
                val = int(match.group(1))
                if 20 <= val <= 100:
                    return match.group(1)
    return ""

def extract_rnfl_table_v3(img, df, dbg=None):
    """
    v3æ–¹å¼: ã€ŒAverage thickness RNFL(Î¼m)ã€ã®ç›´ä¸‹ãƒ†ãƒ¼ãƒ–ãƒ«ã€‚
    è¡Œãƒ©ãƒ™ãƒ«( Total / Superior / Inferior )ã®Yåº§æ¨™ã‚’æ‹¾ã„ã€ãã®å¸¯ã®æ•°å€¤ã‚’å·¦å³ã§å–å¾—ã€‚
    """
    out={"RNFL_Total_OD":"","RNFL_Total_OS":"",
         "RNFL_S_OD":"","RNFL_S_OS":"",
         "RNFL_I_OD":"","RNFL_I_OS":""}

    box, line = bbox_of_line(df, r"Average\s*thickness\s*RNFL")
    if not box: return out

    # ãƒ†ãƒ¼ãƒ–ãƒ«é ˜åŸŸï¼ˆå·¦å³2åˆ—ã¶ã‚“ï¼‹ä½™ç™½ï¼‰ã‚’åºƒã‚ã«åˆ‡ã‚Šå‡ºã—
    x1,y1,x2,y2 = box
    roi = crop_rect(img, x1, y2, x2+650, y2+280, pad=(100,10,100,10))  # ç¯„å›²æ‹¡å¤§
    debug_dump(dbg, "avg_roi", im=roi)

    # ROI å†…ã§å†TSV
    dfr, _ = ocr_df(roi, psm=6)
    if dfr is None or len(dfr)==0: return out

    def y_of(label_regex):
        for (b,p,ln), g in dfr.groupby(["block_num","par_num","line_num"]):
            line=" ".join(g["text"].tolist())
            if re.search(label_regex, line, re.I):
                yy=int(min(g["top"])); hh=int(max(g["top"]+g["height"]))-yy
                return yy + hh/2
        return None

    rows = {
        "Total": y_of(r"Total\s*Thickness|Total|å¹³å‡|Average|TOTAL"),  # ãƒ‘ã‚¿ãƒ¼ãƒ³æ‹¡å¼µ
        "Superior": y_of(r"Superior|ä¸Š|S|Sup|SUPERIOR|ä¸Šæ–¹"),  # ãƒ‘ã‚¿ãƒ¼ãƒ³å¤§å¹…æ‹¡å¼µ
        "Inferior": y_of(r"Inferior|ä¸‹|I|Inf|INFERIOR|ä¸‹æ–¹"),  # ãƒ‘ã‚¿ãƒ¼ãƒ³å¤§å¹…æ‹¡å¼µ
    }
    
    for key, yy in rows.items():
        if yy is None: continue
        vals = pick_row_values(dfr, yy, band=35, expect=2)  # bandèª¿æ•´: 30â†’35
        if key=="Total":
            out["RNFL_Total_OD"], out["RNFL_Total_OS"] = vals
        elif key=="Superior":
            out["RNFL_S_OD"], out["RNFL_S_OS"] = vals
        elif key=="Inferior":
            out["RNFL_I_OD"], out["RNFL_I_OS"] = vals
    
    # è¶…å¼·åŒ–ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šè¡Œã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚° + Total OSç‰¹åˆ¥å‡¦ç†
    if not out["RNFL_Total_OD"] or not out["RNFL_S_OD"] or not out["RNFL_I_OD"] or not out["RNFL_Total_OS"]:
        # å…¨æ•°å€¤ã‚’ Yåº§æ¨™ã§ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°
        all_tokens = numeric_tokens(dfr)
        rnfl_candidates = []
        
        for x, y, w, h, val_str in all_tokens:
            try:
                val = float(val_str)
                if 30 <= val <= 200:  # RNFLå¦¥å½“ç¯„å›²
                    cy = y + h/2
                    rnfl_candidates.append((x, cy, val_str))
            except:
                continue
        
        if len(rnfl_candidates) >= 2:  # æœ€ä½æ¡ä»¶ã‚’ç·©å’Œï¼ˆ4â†’2ï¼‰
            # Yåº§æ¨™ã§ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°
            rnfl_candidates.sort(key=lambda z: z[1])  # Yåº§æ¨™é †
            clusters = []
            band = 45  # ã‚¯ãƒ©ã‚¹ã‚¿å¸¯å¹…ã‚’æ‹¡å¤§ï¼ˆ40â†’45ï¼‰
            
            for x, cy, val_str in rnfl_candidates:
                if not clusters or abs(clusters[-1]["y"] - cy) > band:
                    clusters.append({"y": cy, "vals": [(x, val_str)]})
                else:
                    clusters[-1]["vals"].append((x, val_str))
            
            # å„ã‚¯ãƒ©ã‚¹ã‚¿ã‹ã‚‰å·¦å³ã®å€¤ã‚’æŠ½å‡º
            def extract_lr(cluster_vals):
                cluster_vals.sort(key=lambda z: z[0])  # Xåº§æ¨™é †
                return (cluster_vals[0][1] if len(cluster_vals) > 0 else "", 
                       cluster_vals[1][1] if len(cluster_vals) > 1 else "")
            
            # ä¸Šã‹ã‚‰é †ã«Total, Superior, Inferiorã¨ä»®å®šï¼ˆæ”¹è‰¯ç‰ˆï¼‰
            if len(clusters) >= 1:
                od, os = extract_lr(clusters[0]["vals"])
                # Total ODãŒæœªè¨­å®šã®å ´åˆã®ã¿è¨­å®š
                if not out["RNFL_Total_OD"]:
                    out["RNFL_Total_OD"] = keep_in(od, 60, 150)
                # Total OSã¯ç©æ¥µçš„ã«è¨­å®šï¼ˆç²¾åº¦å‘ä¸Šï¼‰
                if not out["RNFL_Total_OS"] or not out["RNFL_Total_OS"].strip():
                    total_os_candidate = keep_in(os, 60, 150)
                    if total_os_candidate:  # å¦¥å½“ãªå€¤ãŒã‚ã‚Œã°è¨­å®š
                        out["RNFL_Total_OS"] = total_os_candidate
                
            if len(clusters) >= 2 and not out["RNFL_S_OD"]:
                od, os = extract_lr(clusters[1]["vals"])
                out["RNFL_S_OD"] = keep_in(od, 30, 200)
                out["RNFL_S_OS"] = keep_in(os, 30, 200)
                
            if len(clusters) >= 3 and not out["RNFL_I_OD"]:
                od, os = extract_lr(clusters[2]["vals"])
                out["RNFL_I_OD"] = keep_in(od, 30, 200)
                out["RNFL_I_OS"] = keep_in(os, 30, 200)
            
            # Total OSè¶…å¼·åŒ–æ¤œç´¢ï¼ˆè¤‡æ•°æˆ¦ç•¥ï¼‰
            if not out["RNFL_Total_OS"] or not out["RNFL_Total_OS"].strip():
                total_os_found = False
                
                # æˆ¦ç•¥1: æœ€é«˜å€¤ãƒ™ãƒ¼ã‚¹ï¼ˆ80-150ç¯„å›²ï¼‰
                max_os_candidates = []
                for cluster in clusters:
                    _, os_val = extract_lr(cluster["vals"])
                    if os_val:
                        try:
                            val = float(os_val)
                            if 80 <= val <= 150:  # Total RNFLã®å…¸å‹ç¯„å›²
                                max_os_candidates.append((val, os_val))
                        except:
                            continue
                
                if max_os_candidates:
                    max_os_candidates.sort(key=lambda x: x[0], reverse=True)
                    out["RNFL_Total_OS"] = max_os_candidates[0][1]
                    total_os_found = True
                
                # æˆ¦ç•¥2: å˜ç‹¬å€¤æ¤œç´¢ï¼ˆã‚¯ãƒ©ã‚¹ã‚¿ã«é–¢ä¿‚ãªãï¼‰
                if not total_os_found:
                    for x, cy, val_str in rnfl_candidates:
                        try:
                            val = float(val_str)
                            if 90 <= val <= 140:  # ã‚ˆã‚Šå³æ ¼ãªTotalç¯„å›²
                                # Xåº§æ¨™ãŒå³å´ï¼ˆOSå´ï¼‰ã«ã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                                if x > 200:  # çµŒé¨“çš„é–¾å€¤
                                    out["RNFL_Total_OS"] = val_str
                                    total_os_found = True
                                    break
                        except:
                            continue

    # å¦¥å½“åŸŸãƒ•ã‚£ãƒ«ã‚¿ï¼ˆÎ¼mï¼‰
    for k in list(out.keys()):
        out[k] = keep_in(out[k], 30, 200)
    
    # ãƒ‡ãƒãƒƒã‚°æƒ…å ±å‡ºåŠ›
    debug_info = f"ãƒ©ãƒ™ãƒ«ãƒ™ãƒ¼ã‚¹æ¤œå‡º:\n"
    for key, yy in rows.items():
        debug_info += f"{key}: Y={yy}\n"
    
    debug_info += f"\næŠ½å‡ºçµæœ:\n"
    debug_info += f"Total: OD={out['RNFL_Total_OD']}, OS={out['RNFL_Total_OS']}\n"
    debug_info += f"Superior: OD={out['RNFL_S_OD']}, OS={out['RNFL_S_OS']}\n"
    debug_info += f"Inferior: OD={out['RNFL_I_OD']}, OS={out['RNFL_I_OS']}\n"
    
    # ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°æƒ…å ±ã‚‚è¿½åŠ 
    if 'clusters' in locals():
        debug_info += f"\nã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°çµæœ:\n"
        for i, cluster in enumerate(clusters):
            vals_str = [f"({x},{val})" for x, val in cluster["vals"]]
            debug_info += f"ã‚¯ãƒ©ã‚¹ã‚¿{i+1} (Y={cluster['y']:.1f}): {vals_str}\n"
    
    debug_dump(dbg, "rnfl_debug", txt=debug_info)
    
    return out

def extract_disc_topography_v4(img, df, dbg=None):
    """
    v4æ”¹è‰¯ç‰ˆ: ã€ŒDisc Topographyã€ä¸‹ã®è¡¨ã‹ã‚‰æ•°å€¤ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã§Rim/Disc/Cup ã‚’å·¦å³ã§å–å¾—ã€‚
    """
    out={"RimArea_OD_mm2":"","RimArea_OS_mm2":"",
         "DiscArea_OD_mm2":"","DiscArea_OS_mm2":"",
         "CupVolume_OD_mm3":"","CupVolume_OS_mm3":""}

    box,_=bbox_of_line(df, r"Disc\s*Topography")
    if not box: return out
    x1,y1,x2,y2=box

    # è¡¨å…¨ä½“ï¼ˆå·¦å³ã®æ•°å€¤åˆ—ã¾ã§ï¼‰ã‚’ã•ã‚‰ã«åºƒã‚ã« - padæ‹¡å¤§
    roi = crop_rect(img, x1-60, y2, x2+740, y2+320, pad=(130,10,130,10))  # ç¯„å›²å¤§å¹…æ‹¡å¤§
    debug_dump(dbg, "disc_roi", im=roi)

    # æ•°å­—ã ã‘TSVï¼ˆå°æ•°å„ªå…ˆï¼‰
    dfn, _ = ocr_df(roi, psm=6)  # æ–‡å­—åˆ¶é™ãªã—
    if dfn is None or len(dfn)==0: return out

    def _norm_num(s: str) -> str:
        s=s.replace(",",".")
        if s.startswith("."): s="0"+s
        return s

    # å°æ•°å€™è£œï¼ˆ0.00ã€œ4.00ï¼‰
    toks=[]
    for _,r in dfn.iterrows():
        s=_norm_num(str(r["text"]))
        if re.fullmatch(r"\d?\.\d{1,2}", s) or re.fullmatch(r"\d{1}\.\d{1,2}", s) or re.fullmatch(r"\d{1,2}\.\d{1,2}", s):
            try:
                v=float(s)
                if 0.0<=v<=4.0:
                    cx=r["left"]+r["width"]/2; cy=r["top"]+r["height"]/2
                    toks.append((cx,cy,"%.2f"%v))
            except: pass
    if not toks: return out

    # è¡Œã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ï¼ˆæ…é‡ãªæ”¹è‰¯ç‰ˆï¼‰
    toks.sort(key=lambda z:z[1])
    rows=[]; band=35  # å…ƒã®35pxã«æˆ»ã™
    for cx,cy,s in toks:
        if not rows or abs(rows[-1]["y"]-cy)>band:
            rows.append({"y":cy,"vals":[(cx,s)]})
        else:
            rows[-1]["vals"].append((cx,s))

    # è¡Œæ•°ã¯6è¡Œã«æˆ»ã™ï¼ˆå®‰å®šæ€§é‡è¦–ï¼‰
    rows=rows[:6]
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã¯è¡Œã‚ãªã„ï¼ˆå…ƒã®å‹•ä½œã‚’ç¶­æŒï¼‰

    def two_enhanced(vals):
        """å®‰å®šç‰ˆï¼šåŸºæœ¬æ©Ÿèƒ½+è»½å¾®ãªæ”¹è‰¯ã®ã¿"""
        vals=sorted(vals, key=lambda z:z[0])  # Xåº§æ¨™é †
        arr=[v for _,v in vals]
        
        # åŸºæœ¬çš„ã«ã¯å…ƒã®two()ã¨åŒã˜å‹•ä½œ
        return (arr[0] if len(arr)>0 else "", arr[1] if len(arr)>1 else "")

    if len(rows)>=1:  # Rim Area
        od,os=two_enhanced(rows[0]["vals"])
        out["RimArea_OD_mm2"]=od; out["RimArea_OS_mm2"]=os
    if len(rows)>=2:  # Disc Area
        od,os=two_enhanced(rows[1]["vals"])
        out["DiscArea_OD_mm2"]=od; out["DiscArea_OS_mm2"]=os
    
    # Cup Volume: ã‚ˆã‚ŠæŸ”è»Ÿãªè¡Œä½ç½®ç‰¹å®š
    # 1. ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã§Cupè¡Œã‚’æ¢ã™
    cup_found = False
    for i, row in enumerate(rows):
        # å„è¡Œã®å€¤ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¦ã€Cup Volumeã‚‰ã—ã„å€¤ï¼ˆ0.0-1.5ç¯„å›²ï¼‰ãŒã‚ã‚‹ã‹
        for _, val_str in row["vals"]:
            try:
                val = float(val_str)
                if 0.0 <= val <= 1.5:  # Cup Volumeã®å¦¥å½“ç¯„å›²
                    od, os = two_enhanced(row["vals"])
                    out["CupVolume_OD_mm3"] = keep_in(od, 0.0, 1.5)
                    out["CupVolume_OS_mm3"] = keep_in(os, 0.0, 1.5)
                    cup_found = True
                    break
            except:
                continue
        if cup_found:
            break
    
    # 2. ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã§è¦‹ã¤ã‹ã‚‰ãªã‘ã‚Œã°ã€å¾“æ¥ã®ä½ç½®ãƒ™ãƒ¼ã‚¹ï¼ˆ3-6è¡Œç›®ã‚’è©¦è¡Œï¼‰
    if not cup_found:
        for cup_row_idx in [2, 3, 4, 5]:  # å…ƒã®3-6è¡Œç›®ã«æˆ»ã™
            if len(rows) > cup_row_idx and not out["CupVolume_OD_mm3"]:
                od,os=two_enhanced(rows[cup_row_idx]["vals"])
                # Cupã¯ 0.00ã€œ1.50 ã®å¦¥å½“åŸŸã§ãƒ•ã‚£ãƒ«ã‚¿
                try:
                    od_val = float(od) if od else None
                    os_val = float(os) if os else None
                    if (od_val and 0.0 <= od_val <= 1.5) or (os_val and 0.0 <= os_val <= 1.5):
                        out["CupVolume_OD_mm3"] = od if od_val and 0.0 <= od_val <= 1.5 else ""
                        out["CupVolume_OS_mm3"] = os if os_val and 0.0 <= os_val <= 1.5 else ""
                        break
                except:
                    continue
    
    # ãƒ‡ãƒãƒƒã‚°æƒ…å ±
    debug_info = f"æ¤œå‡ºã•ã‚ŒãŸè¡Œæ•°: {len(rows)}\n"
    for i, row in enumerate(rows):
        debug_info += f"è¡Œ{i+1}: {[v for _,v in row['vals']]}\n"
    debug_dump(dbg, "disc_rows", txt=debug_info)
    
    return out

def extract_quad_optional_v3(img, df, dbg=None):
    """
    v3æ”¹è‰¯ç‰ˆ: T/N ã‚’å††ã‚°ãƒ©ãƒ•ä»˜è¿‘ã‹ã‚‰æ‹¾ã†ï¼ˆè¤‡æ•°ä½ç½®ãƒ»PSMãƒ»ç¯„å›²æ‹¡å¤§ï¼‰
    """
    out={"RNFL_T_OD":"","RNFL_T_OS":"","RNFL_N_OD":"","RNFL_N_OS":""}
    box, _ = bbox_of_line(df, r"Average\s*thickness\s*RNFL")
    if not box: return out
    x1,y1,x2,y2 = box
    H,W = img.shape[:2]
    
    # è¤‡æ•°ã®å††ã‚°ãƒ©ãƒ•ä½ç½®å€™è£œã‚’è©¦è¡Œï¼ˆæ”¹è‰¯ï¼‰
    left_candidates = [
        crop_rect(img, x1-120, y2+10, x1+200, y2+220, pad=(30,0,30,0)),  # æ‹¡å¤§ç‰ˆ1
        crop_rect(img, x1-80, y2+20, x1+160, y2+190, pad=(20,0,20,0)),   # å¾“æ¥ç‰ˆ
        crop_rect(img, x1-100, y2+30, x1+180, y2+200, pad=(25,0,25,0)),  # ä¸­é–“ç‰ˆ
    ]
    
    right_candidates = [
        crop_rect(img, x2-250, y2+10, x2+100, y2+220, pad=(30,0,30,0)),  # æ‹¡å¤§ç‰ˆ1
        crop_rect(img, x2-200, y2+20, x2+60,  y2+190, pad=(20,0,20,0)),  # å¾“æ¥ç‰ˆ
        crop_rect(img, x2-220, y2+30, x2+80,  y2+200, pad=(25,0,25,0)),  # ä¸­é–“ç‰ˆ
    ]
    
    # ãƒ‡ãƒãƒƒã‚°ç”¨ã«æœ€å¤§ç‰ˆã‚’ä¿å­˜
    debug_dump(dbg, "quad_left_enhanced",  im=left_candidates[0])
    debug_dump(dbg, "quad_right_enhanced", im=right_candidates[0])
    debug_dump(dbg, "quad_left",  im=left_candidates[1])  # å¾“æ¥ç‰ˆã‚‚ä¿æŒ
    debug_dump(dbg, "quad_right", im=right_candidates[1])
    
    def extract_best_nums(candidates, side_name):
        best_result = ("", "")
        best_score = 0
        debug_info = f"{side_name}å´æ¤œå‡ºçµæœ:\n"
        
        for i, im in enumerate(candidates):
            # è¤‡æ•°PSMãƒ¢ãƒ¼ãƒ‰ã§è©¦è¡Œ
            for psm in [6, 8, 13]:
                try:
                    df2,_ = ocr_df(im, psm=psm)
                    if df2 is None or len(df2)==0: continue
                    
                    vals=[]
                    for _,r in df2.iterrows():
                        s=str(r["text"])
                        if re.fullmatch(r"\d{2,3}", s):
                            try:
                                v=int(s)
                                if 30<=v<=200:  # RNFLå¦¥å½“ç¯„å›²
                                    conf = r.get('conf', 50)  # ä¿¡é ¼åº¦å–å¾—
                                    vals.append((s, conf, r['left'], r['top']))
                            except:
                                pass
                    
                    # OSã‚µã‚¤ãƒ‰ï¼ˆå³å††ï¼‰ã®ç‰¹åˆ¥å‡¦ç†
                    if side_name == "OS" and len(vals) >= 1:
                        # OSã‚µã‚¤ãƒ‰ã¯T/Né †åºãŒé€†ã«ãªã‚‹ã“ã¨ãŒã‚ã‚‹
                        # Yåº§æ¨™ã§ã¾ãšã‚½ãƒ¼ãƒˆã€æ¬¡ã«Xåº§æ¨™
                        vals.sort(key=lambda x: (x[3], x[2]))
                        
                        # ç‰¹ã«T_OSï¼ˆTemporalï¼‰ã®æ¤œå‡ºå¼·åŒ–
                        if len(vals) >= 2:
                            # 2ã¤ã®å€¤ãŒã‚ã‚‹å ´åˆã€å·¦å´ã‚’Tã€å³å´ã‚’Nã¨ã™ã‚‹
                            t_val, n_val = vals[0][0], vals[1][0]
                            score = sum(v[1] for v in vals[:2])
                            debug_info += f"  å€™è£œ{i+1}-PSM{psm}(OSç‰¹åˆ¥): T={t_val}, N={n_val} (score:{score:.1f})\n"
                            
                            if score > best_score:
                                best_result = (t_val, n_val)
                                best_score = score
                        elif len(vals) == 1:
                            # 1ã¤ã—ã‹ãªã„å ´åˆã€Tä½ç½®ã¨ã—ã¦æ‰±ã†
                            t_val = vals[0][0]
                            score = vals[0][1]
                            debug_info += f"  å€™è£œ{i+1}-PSM{psm}(OSå˜ç‹¬): T={t_val} (score:{score:.1f})\n"
                            
                            if score > best_score:
                                best_result = (t_val, "")
                                best_score = score
                    else:
                        # ODã‚µã‚¤ãƒ‰ã¯å¾“æ¥é€šã‚Š
                        vals.sort(key=lambda x: (x[3], x[2]))  # Yåº§æ¨™ã€Xåº§æ¨™é †
                        
                        if len(vals) >= 2:
                            score = sum(v[1] for v in vals[:2])  # ä¸Šä½2ã¤ã®ä¿¡é ¼åº¦åˆè¨ˆ
                            debug_info += f"  å€™è£œ{i+1}-PSM{psm}: {[v[0] for v in vals[:2]]} (score:{score:.1f})\n"
                            
                            if score > best_score:
                                best_result = (vals[0][0], vals[1][0])
                                best_score = score
                    
                except Exception as e:
                    continue
        
        debug_info += f"  æœ€çµ‚é¸æŠ: {best_result} (score:{best_score:.1f})\n"
        debug_dump(dbg, f"quad_{side_name.lower()}_debug", txt=debug_info)
        return best_result
    
    # å·¦å††ï¼ˆODï¼‰ã¨å³å††ï¼ˆOSï¼‰ã§æœ€é©æŠ½å‡º
    t_od, n_od = extract_best_nums(left_candidates, "OD")
    t_os, n_os = extract_best_nums(right_candidates, "OS")
    
    out["RNFL_T_OD"], out["RNFL_N_OD"] = t_od, n_od
    out["RNFL_T_OS"], out["RNFL_N_OS"] = t_os, n_os
    
    return out

def is_disc_oct(df):
    """OCT Disc vs Macular ã®åˆ¤å®š"""
    all_text = " ".join([str(r["text"]) for _, r in df.iterrows()]).upper()
    
    # Disc OCTã®ç‰¹å¾´çš„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
    disc_keywords = ["AVERAGE THICKNESS RNFL", "DISC TOPOGRAPHY", "RNFL THICKNESS", "OPTIC DISC"]
    # Macular OCTã®ç‰¹å¾´çš„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰  
    macular_keywords = ["THICKNESS MAP", "MACULAR", "FOVEA", "CENTRAL THICKNESS"]
    
    disc_score = sum(1 for kw in disc_keywords if kw in all_text)
    macular_score = sum(1 for kw in macular_keywords if kw in all_text)
    
    return disc_score > macular_score

def process_one(p: Path, out_rows: list, debug=False):
    print(f"ğŸ” å‡¦ç†ä¸­: {p.name}")
    img = read_img(p)
    if img is None:
        print(f"âŒ ç”»åƒèª­ã¿è¾¼ã¿å¤±æ•—: {p}")
        out_rows.append({"ã‚½ãƒ¼ã‚¹":p.name})
        return
        
    df, _ = ocr_df(img, psm=6)
    if df is None or len(df)==0:
        print(f"âŒ OCRå¤±æ•—: {p}")
        out_rows.append({"ã‚½ãƒ¼ã‚¹":p.name})
        return
    
    # OCTç¨®åˆ¥åˆ¤å®š
    if not is_disc_oct(df):
        print(f"â­ï¸  Macular OCTã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—: {p.name}")
        out_rows.append({"ã‚½ãƒ¼ã‚¹":p.name, "å‚™è€ƒ":"Macular OCT - ã‚¹ã‚­ãƒƒãƒ—"})
        return
        
    print(f"ğŸ“„ OCRãƒ‡ãƒ¼ã‚¿è¡Œæ•°: {len(df)} (Disc OCT)")
    dbg = (Path("debug")/p.stem) if debug else None

    ss_od, ss_os = extract_ss(df)
    print(f"âœ… Signal Strength: OD={ss_od}, OS={ss_os}")
    
    # v3æ–¹å¼ã§RNFLæŠ½å‡º
    rnfl = extract_rnfl_table_v3(img, df, dbg)
    rnfl_count = sum(1 for v in rnfl.values() if v)
    print(f"âœ… RNFLæŠ½å‡º(v3): {rnfl_count}/6å€‹ã®å€¤")
    
    # v4æ”¹è‰¯ç‰ˆã§TopographyæŠ½å‡º
    topo = extract_disc_topography_v4(img, df, dbg)
    topo_count = sum(1 for v in topo.values() if v)
    print(f"âœ… TopographyæŠ½å‡º(v4æ”¹): {topo_count}/6å€‹ã®å€¤")
    
    # v3æ–¹å¼ã§QuadrantæŠ½å‡º
    quad = extract_quad_optional_v3(img, df, dbg)
    quad_count = sum(1 for v in quad.values() if v)
    print(f"âœ… QuadrantæŠ½å‡º(v3): {quad_count}/4å€‹ã®å€¤")

    row = {"ã‚½ãƒ¼ã‚¹":p.name, "SS_OD":ss_od, "SS_OS":ss_os, **rnfl, **topo, **quad}
    out_rows.append(row)
    print("âœ… å‡¦ç†å®Œäº†\n")

def main():
    ap=argparse.ArgumentParser(description="Topcon OCT Disc Report æŠ½å‡º Hybridï¼ˆv3+v4æ”¹è‰¯ï¼‰")
    ap.add_argument("patterns", nargs="+", help="ç”»åƒãƒ‘ã‚¹ï¼ˆãƒ¯ã‚¤ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ‰å¯ï¼‰")
    ap.add_argument("--out", default="oct_disc_hybrid.csv")
    ap.add_argument("--debug", action="store_true")
    args=ap.parse_args()

    print(f"ğŸ”¬ Topcon OCT Disc Hybrid - {len(args.patterns)}ãƒ‘ã‚¿ãƒ¼ãƒ³å‡¦ç†")
    if args.debug:
        print("ğŸ› ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰: debug/<ç”»åƒå>/ã«ROIç”»åƒä¿å­˜")
    print("=" * 60)

    out=[]
    for pat in args.patterns:
        try:
            # çµ¶å¯¾ãƒ‘ã‚¹ã®å ´åˆã®å‡¦ç†
            if os.path.isabs(pat):
                files = [Path(f) for f in glob.glob(pat)]
            else:
                files = list(Path().glob(pat))
        except Exception as e:
            print(f"âŒ ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚¨ãƒ©ãƒ¼ '{pat}': {e}")
            files = []
        
        print(f"ğŸ“‚ ãƒ‘ã‚¿ãƒ¼ãƒ³ '{pat}': {len(files)}ãƒ•ã‚¡ã‚¤ãƒ«")
        for p in files:
            process_one(p, out, debug=args.debug)

    cols=["ã‚½ãƒ¼ã‚¹","å‚™è€ƒ","SS_OD","SS_OS",
          "RNFL_Total_OD","RNFL_Total_OS","RNFL_S_OD","RNFL_S_OS","RNFL_I_OD","RNFL_I_OS",
          "RimArea_OD_mm2","DiscArea_OD_mm2","CupVolume_OD_mm3",
          "RimArea_OS_mm2","DiscArea_OS_mm2","CupVolume_OS_mm3",
          "RNFL_T_OD","RNFL_T_OS","RNFL_N_OD","RNFL_N_OS"]
    
    with open(args.out,"w",encoding=ENC,newline="") as f:
        w=csv.DictWriter(f, fieldnames=cols); w.writeheader(); w.writerows(out)
    
    print("=" * 60)
    print(f"âœ… å‡ºåŠ›å®Œäº†: {args.out}")
    print(f"ğŸ“Š å‡¦ç†ä»¶æ•°: {len(out)}ä»¶")
    
    # çµæœã‚µãƒãƒªãƒ¼
    if out:
        filled_counts = {}
        for col in cols[1:]:  # ã‚½ãƒ¼ã‚¹ä»¥å¤–
            filled_counts[col] = sum(1 for row in out if row.get(col, ""))
        
        print("\nğŸ“ˆ æŠ½å‡ºæˆåŠŸç‡:")
        for col, count in filled_counts.items():
            rate = count / len(out) * 100
            print(f"  {col}: {count}/{len(out)} ({rate:.1f}%)")

if __name__=="__main__":
    main()
